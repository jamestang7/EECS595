{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import unittest\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.autograd import Variable\n",
    "def load_embedding(filename='glove.6B.50d.txt'):\n",
    "    \"\"\"\n",
    "    Load embedding for the training and\n",
    "    :return: dataframe, words\n",
    "    \"\"\"\n",
    "    # creat column names\n",
    "    num = np.arange(51)\n",
    "    num_str = list(map(str, num))\n",
    "    list_name = list(map(lambda x: \"dim_\" + x, num_str))\n",
    "    df = pd.read_csv(\"glove.6B.50d.txt\", sep=\" \", quoting=csv.QUOTE_NONE,\n",
    "                     header=None, encoding='utf-8',\n",
    "                     names=list_name)\n",
    "    df.rename({'dim_0': 'token'}, axis=1, inplace=True)\n",
    "    words = df.token.to_list()\n",
    "    # add padding embedding\n",
    "    df.loc['<PAD>'] = np.zeros(50)\n",
    "    df.set_index('token', inplace=True)\n",
    "    df.to_pckle(\"glove.pkl\")\n",
    "    return df, words\n",
    "def word_to_embedding(target_vocab, pre_train):\n",
    "    \"\"\"\n",
    "\n",
    "    :param pre_train: pd.DataFrame pre-trained dataframe\n",
    "    :param target_vocab: list/ array of tokens need to be transformed\n",
    "    :return: transformed matrix, result dictionary for the unique tokens\n",
    "    \"\"\"\n",
    "    matrix_len = len(target_vocab)\n",
    "    weighted_matrix = np.zeros((matrix_len + 1, 50))\n",
    "    words_found = 0\n",
    "    for i, word in enumerate(target_vocab):\n",
    "        try:\n",
    "            weighted_matrix[i] = pre_train.loc[word]\n",
    "            words_found += 1\n",
    "        except KeyError:\n",
    "            weighted_matrix[i] = np.random.normal(size=50)\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Finished {}th words\".format(i))\n",
    "    return weighted_matrix\n",
    "def create_emb_layer(weighted_matrix1, non_trainable=False):\n",
    "    \"\"\"\n",
    "\n",
    "    :param weighted_matrix1: tensor matrix\n",
    "    :param non_trainable:\n",
    "    :return: emb_layer type embedding\n",
    "    \"\"\"\n",
    "    input_shape, embedding_dim = weighted_matrix1.shape\n",
    "    emb_layer = nn.Embedding.from_pretrained(weighted_matrix1,\n",
    "                                             padding_idx=input_shape - 1)\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "    return emb_layer\n",
    "def split_text(text_file):\n",
    "    \"\"\"\n",
    "\n",
    "    :param text_file: training file\n",
    "    :return: DIC, TOKENS and TAGS\n",
    "\n",
    "    \"\"\"\n",
    "    with open(text_file, mode=\"r\") as file:\n",
    "        text_f = file.read()\n",
    "        text_f_lst = text_f.split()\n",
    "        file.close()\n",
    "    keys, values = text_f_lst[::2], text_f_lst[1::2]\n",
    "    result_dic = dict(zip(keys, values))\n",
    "    return result_dic, keys, values\n",
    "def prepare_seq(seq_list, dictionary):\n",
    "    \"\"\"\n",
    "    embedding and padded a sequence, given its relating dictionary\n",
    "    :return: padded sequence in numerical numbers\n",
    "    \"\"\"\n",
    "    embedded = []\n",
    "    for batch in seq_list:\n",
    "        empty_lst = [dictionary[tag] for tag in batch]\n",
    "        embedded.append(empty_lst)\n",
    "    # convert to a list of tensor\n",
    "    embedded = [torch.tensor(seq) for seq in embedded]\n",
    "    padded = nn.utils.rnn.pad_sequence(embedded,\n",
    "                                       batch_first=True,\n",
    "                                       padding_value=dictionary['<PAD>'])\n",
    "    return padded"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, nb_layers, batch_size, nb_lstm_units, embedding_layer,\n",
    "                 bidirectional=False,\n",
    "                 dropout=0,\n",
    "                 embedding_dim=50):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_layer = None\n",
    "        self.result_dic, self.words_lst, self.tags_lst = split_text(\"wsj1-18.training\")\n",
    "        self.vocab = dict(zip(sorted(set(self.words_lst)),\n",
    "                              np.arange(len(set(self.words_lst)))))\n",
    "        self.tags = dict(zip(sorted(set(self.tags_lst)),\n",
    "                             np.arange(len(set(self.tags_lst)))))\n",
    "        self.vocab['<PAD>'] = len(set(self.words_lst))\n",
    "        self.tags['<PAD>'] = len(set(self.tags_lst))\n",
    "        self.padding_idx = self.vocab['<PAD>']\n",
    "        self.nb_layers = nb_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_lstm_units = nb_lstm_units\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_layer = embedding_layer\n",
    "        self.bidirectional = bidirectional\n",
    "        self.dropout = dropout if nb_layers > 1 else 0\n",
    "        self.dropout_layer = nn.Dropout(self.dropout)\n",
    "        # don't count the pad for the tags\n",
    "        self.nb_tags = len(self.tags) - 1\n",
    "\n",
    "        # build actual NN\n",
    "        self.__build_model()\n",
    "\n",
    "    def __build_model(self):\n",
    "        # design LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.nb_lstm_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.nb_layers,\n",
    "            bidirectional=self.bidirectional,\n",
    "            dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        # output layer which project back to tag space\n",
    "        self.hidden_to_tag = nn.Linear(self.nb_lstm_units * 2\n",
    "                                       if self.bidirectional\n",
    "                                       else self.nb_lstm_units\n",
    "                                       , self.nb_tags)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # init hidden layers and input sequence length\n",
    "        h0 = torch.rand(self.nb_layers, input.size(0), self.nb_lstm_units)\n",
    "        c0 = torch.rand(self.nb_layers, input.size(0), self.nb_lstm_units)\n",
    "        input_lengths = torch.all(input != self.padding_idx, dim=2)\\\n",
    "            .sum(dim=1).flatten()\n",
    "\n",
    "        # -------------------\n",
    "        # 1. embed the input\n",
    "        # Dim transformation: (batch_size, seq_len, 1) -> (batch_size, seq_len,\n",
    "        # embedding_dim)\n",
    "        input = self.dropout_layer(self.embedding_layer(input))\n",
    "        input = input.squeeze(2)\n",
    "        # -------------------\n",
    "        # 2.  Run through LSTM\n",
    "        # Dim transformation: (B,L, embedding_dim) -> (B, L, LSTM_units)\n",
    "        input = torch.nn.utils.rnn.pack_padded_sequence(input,\n",
    "                                                        input_lengths,\n",
    "                                                        batch_first=True,\n",
    "                                                        enforce_sorted=False)\n",
    "        # now run through LSTM\n",
    "        input = input.float()\n",
    "        out, (h0, c0) = self.lstm(input, (h0, c0))  # undo the packing operation\n",
    "        out, len_unpacked = nn.utils.rnn.pad_packed_sequence(out,\n",
    "                                                             batch_first=True)\n",
    "        # -------------------\n",
    "        # 3.  Apply FC linear layer\n",
    "        # linear layer\n",
    "        out = out.view(-1,\n",
    "                       out.size(-1))  # (batch_size, seq_len, nb_lstm_units) -> (batch_size * seq_len, nb_lstm_units)\n",
    "        out = self.hidden_to_tag(out)  # (batch_size * seq_len, nb_lstm_units) -> (batch_size * seq_len, nb_tags)\n",
    "\n",
    "        # reshape into (batch_size,  seq_len, nb_lstm_units)\n",
    "        out = out.view(self.batch_size, -1, self.nb_tags)\n",
    "        # -------------------\n",
    "        # 4.  softmax to transfer it to probability\n",
    "        Y_hat = F.log_softmax(out.float(), dim=2)\n",
    "        return Y_hat\n",
    "\n",
    "    def loss(self, Y_hat, Y):\n",
    "        # NLL(tensor log_softmax output, target index list)\n",
    "        # flatten out all labels\n",
    "        Y = prepare_seq(Y, self.tags)\n",
    "        Y = Y.flatten()\n",
    "        # flatten all predictions\n",
    "        Y_hat = Y_hat.view(-1, len(self.tags) - 1)\n",
    "        # create a mask that filter '<PAD>;\n",
    "        tag_token = self.tags['<PAD>']\n",
    "        mask = (Y < tag_token)\n",
    "        mask_idx = torch.nonzero(mask.float())\n",
    "        Y_hat = Y_hat[mask_idx].squeeze(1)\n",
    "        Y = Y[mask_idx].squeeze(1)\n",
    "        loss = nn.NLLLoss()\n",
    "        result = loss(Y_hat, Y)\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "### transform text into list of words\n",
    "df = pd.read_pickle('glove.pkl')\n",
    "_, words_lst, tags_lst = split_text(\"wsj1-18.training\")\n",
    "tags = dict(zip(sorted(set(tags_lst)), np.arange(len(set(tags_lst)))))\n",
    "tags['<PAD>'] = len(tags)\n",
    "weighted_matrix = torch.load(\"weighed_matrix.pt\")\n",
    "embedding_layer_const = create_emb_layer(weighted_matrix)\n",
    "nb_layers = 2\n",
    "nb_lstm_units = 32\n",
    "batch_size = 3\n",
    "seq_len = 4\n",
    "padding_idx = 912344\n",
    "toy_training = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[172], line 22\u001B[0m\n\u001B[1;32m     16\u001B[0m model \u001B[38;5;241m=\u001B[39m LSTM(nb_layers\u001B[38;5;241m=\u001B[39mnb_layers,\n\u001B[1;32m     17\u001B[0m              batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m,\n\u001B[1;32m     18\u001B[0m              nb_lstm_units\u001B[38;5;241m=\u001B[39mnb_lstm_units,\n\u001B[1;32m     19\u001B[0m              embedding_layer\u001B[38;5;241m=\u001B[39membedding_layer_const,\n\u001B[1;32m     20\u001B[0m              bidirectional\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m     21\u001B[0m iter1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(train_loader)\n\u001B[0;32m---> 22\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[28], line 49\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;66;03m# init hidden layers and input sequence length\u001B[39;00m\n\u001B[0;32m---> 49\u001B[0m     h0 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnb_layers, \u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnb_lstm_units)\n\u001B[1;32m     50\u001B[0m     c0 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnb_layers, \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnb_lstm_units)\n\u001B[1;32m     51\u001B[0m     input_lengths \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mall(\u001B[38;5;28minput\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_idx, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\\\n\u001B[1;32m     52\u001B[0m         \u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mflatten()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "batch_in = torch.tensor([[[4],\n",
    "                          [5],\n",
    "                          [912344],\n",
    "                          [912344]],\n",
    "\n",
    "                         [[6],\n",
    "                          [912344],\n",
    "                          [912344],\n",
    "                          [912344]],\n",
    "\n",
    "                         [[7],\n",
    "                          [8],\n",
    "                          [9],\n",
    "                          [10]]])\n",
    "Y = [[\"CC\", \"CD\", \"DT\"], [\"EX\"], [\"JJ\", \"IN\", \"JJ\", \"JJR\"]]\n",
    "model = LSTM(nb_layers=nb_layers,\n",
    "             batch_size=32,\n",
    "             nb_lstm_units=nb_lstm_units,\n",
    "             embedding_layer=embedding_layer_const,\n",
    "             bidirectional=False)\n",
    "iter1 = iter(train_loader)\n",
    "out = model(features)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 4, 45])"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[32],\n         [32],\n         [32],\n         [20]],\n\n        [[13],\n         [14],\n         [14],\n         [20]],\n\n        [[13],\n         [14],\n         [14],\n         [14]]])"
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.max(dim=2, keepdim=True)[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "out = model(batch_in)\n",
    "# out = out.max(dim=2, keepdim=True)[1]\n",
    "Y = [[\"CC\", \"CD\", \"DT\"], [\"EX\"], [\"JJ\", \"IN\", \"JJ\", \"JJR\"]]\n",
    "# NLL(tensor log_softmax output, target index list)\n",
    "# flatten out all labels\n",
    "Y = prepare_seq(Y, tags)\n",
    "Y = Y.flatten()\n",
    "# flatten all predictions\n",
    "out = out.view(-1, len(tags) - 1)\n",
    "# create a mask that filter '<PAD>;\n",
    "tag_token = tags['<PAD>']\n",
    "mask = (Y < tag_token)\n",
    "mask_idx = torch.nonzero(mask.float())\n",
    "out = out[mask_idx].squeeze(1)\n",
    "Y = Y[mask_idx].squeeze(1)\n",
    "loss = nn.NLLLoss()\n",
    "result = loss(out, Y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class SquareDataset(Dataset):\n",
    "     def __init__(self, a=0, b=1):\n",
    "         super(Dataset, self).__init__()\n",
    "         assert a <= b\n",
    "         self.a = a\n",
    "         self.b = b\n",
    "\n",
    "     def __len__(self):\n",
    "         return self.b - self.a + 1\n",
    "\n",
    "     def __getitem__(self, index):\n",
    "        assert self.a <= index <= self.b\n",
    "        return index, index**2\n",
    "\n",
    "data_train = SquareDataset(a=1,b=64)\n",
    "data_train_loader = DataLoader(data_train, batch_size=64, shuffle=True)\n",
    "print(len(data_train))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TagDataset(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        \"\"\"\n",
    "\n",
    "        :param train: bool, if True read training data, else read testing data\n",
    "        \"\"\"\n",
    "        self.train = train\n",
    "        if self.train:\n",
    "            with open(\"wsj1-18.training\", mode=\"r\") as file:\n",
    "                self.text_f = file.read()\n",
    "                self.text_f_lst = self.text_f.splitlines()\n",
    "                file.close()\n",
    "        else:\n",
    "            with open(\"wsj19-21.truth\", mode=\"r\") as file:\n",
    "                self.text_f = file.read()\n",
    "                self.text_f_lst = self.text_f.splitlines()\n",
    "                file.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_f_lst)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.text_f_lst[item].split()[0::2], self.text_f_lst[item].split()[1::2]\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# todo: prepare dataloader for text\n",
    "train_loader = DataLoader(TagDataset(train=True),\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "test_loader = DataLoader(TagDataset(train=False),\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "iter1 = iter(train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[181], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m x, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miter1\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 628\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    631\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    670\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 671\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    672\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    673\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:61\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     60\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 61\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:265\u001B[0m, in \u001B[0;36mdefault_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[1;32m    205\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001B[39;00m\n\u001B[1;32m    207\u001B[0m \u001B[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 265\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:143\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    140\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 143\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:143\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    140\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 143\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:139\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    137\u001B[0m elem_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mnext\u001B[39m(it))\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;28mlen\u001B[39m(elem) \u001B[38;5;241m==\u001B[39m elem_size \u001B[38;5;28;01mfor\u001B[39;00m elem \u001B[38;5;129;01min\u001B[39;00m it):\n\u001B[0;32m--> 139\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meach element in list of batch should be of equal size\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    140\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n",
      "\u001B[0;31mRuntimeError\u001B[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "x, y = next(iter1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}